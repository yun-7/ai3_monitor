import streamlit as st
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from pylab import matplotlib
from matplotlib import font_manager
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime

st.set_page_config(
    page_title="ç³»çµ±ç›£æ§å„€è¡¨æ¿",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("ç›£æ§æ—¥èªŒè¡¨")
st.header(':grey[]', divider='rainbow')
st.markdown('[*é›²ç«¯ç¶­è­·çµ„*](https://gemfor.sharepoint.com/:x:/r/sites/cloud-support/17/%E5%80%BC%E7%8F%AD%E7%9B%A3%E6%8E%A7%E6%97%A5%E8%AA%8C/%E4%BE%8B%E8%A1%8C%E5%B7%A5%E4%BD%9C%20%E6%97%A5/202410%E7%9B%A3%E6%8E%A7%E6%97%A5%E8%AA%8C/EXCEL/10%E6%9C%88%E7%9B%A3%E6%8E%A7%E6%97%A5%E8%AA%8C.xlsx?d=w7fc1a66db73f496eb9b0e95877d23dd6&csf=1&web=1&e=myxWU2)')



def load_data():
    # æª”æ¡ˆä¸Šå‚³åŠŸèƒ½
    uploaded_file = st.file_uploader("é¸æ“‡ä¸€å€‹ CSV æˆ– Excel æª”æ¡ˆ", type=['csv', 'xlsx', 'xls'])
    
    if uploaded_file is not None:
        try:
            # æ ¹æ“šæª”æ¡ˆé¡å‹è®€å–è³‡æ–™
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file)
                df = df[df["ä¸»ç®¡æˆ–è™•ç†äººå›æ‡‰"].notna()]
            else:
                df = pd.read_excel(uploaded_file)
                df = df[df["ä¸»ç®¡æˆ–è™•ç†äººå›æ‡‰"].notna()]
            
            # è½‰æ›æ—¥æœŸæ™‚é–“åˆ—
            df['ç™¼ç”Ÿæ—¥æœŸ'] = pd.to_datetime(df['ç™¼ç”Ÿæ—¥æœŸ'])
            df['æ—¥æœŸ'] = df['ç™¼ç”Ÿæ—¥æœŸ'].dt.date
            df['æ™‚é–“'] = df['ç™¼ç”Ÿæ—¥æœŸ'].dt.time
            df['é€±'] = df['ç™¼ç”Ÿæ—¥æœŸ'].dt.isocalendar().week
            df['æœˆä»½'] = df['ç™¼ç”Ÿæ—¥æœŸ'].dt.month
            
            return df
            
        except Exception as e:
            st.error(f'è®€å–æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}')
            return None
    return None

def calculate_stats(df):
    stats = {
        'CPU': {
            'VM CPU\n>90%': len(df[df['ç•°å¸¸è¨Šæ¯'].str.contains(r'High CPU utilization \(over 90% for 5m\)', regex=True, na=False)]),
            'RDS CPU\n>85%': len(df[df['ç•°å¸¸è¨Šæ¯'].str.contains(r'AWS RDS: High CPU utilization \(over 85% for 15m\)', regex=True, na=False)]),
        },
        'è¨˜æ†¶é«”': {
            'JVM\n>80%': len(df[df['ç•°å¸¸è¨Šæ¯'].str.contains('JVM', regex=True, na=False)]),
            'ä¸»æ©Ÿå¯ç”¨è¨˜æ†¶é«”\n<500mb': len(df[df['ç•°å¸¸è¨Šæ¯'].str.contains(r'Lack of available memory \(<500M', regex=True, na=False)]),
        },
        'ç¡¬ç¢Ÿ': {
            'å¯ç”¨ç©ºé–“\n>80%': len(df[df['ç•°å¸¸è¨Šæ¯'].str.contains('ç£ç¢Ÿ', regex=True, na=False)]),
        },
        'ç¶²é ': {
            'ç¶²é ç„¡æ³•<br>é€£ç·š': len(df[df['ç•°å¸¸è¨Šæ¯'].str.contains('ç¶²é ', na=False)]),
        }
    }
    return stats

def get_unique_error_types(df):
    # å®šç¾©ä¸»è¦éŒ¯èª¤é¡å‹çš„é—œéµå­—åŠå…¶å°æ‡‰çš„å‹å¥½åç¨±
    error_types = {
        'JVM': 'ECP-JVMä½æ–¼20%',
        'AWS RDS': 'AWS RDS',
        'swap': 'swap',
        'ç£ç¢Ÿç©ºé–“': 'ç£ç¢Ÿ',
        'Interface': 'Link down',
        'ICMP': 'ICMP',
        'Web': 'ç¶²é ',
        'memory < 500M': '<500M',
        'CPU >90%': r'High CPU utilization \(over 90% for 5m\)'
    }
    return error_types

def filter_data_host(df, start_date, end_date, exclude_hosts):
    """éæ¿¾æ•¸æ“šåŸºæ–¼æ—¥æœŸç¯„åœå’Œæ’é™¤çš„ä¸»æ©Ÿ"""
    # è½‰æ›æ—¥æœŸæ ¼å¼ç¢ºä¿å¯ä»¥æ¯”è¼ƒ
    start_date = pd.to_datetime(start_date)
    end_date = pd.to_datetime(end_date)
    
    # éæ¿¾æ—¥æœŸç¯„åœ
    mask = (df['ç™¼ç”Ÿæ—¥æœŸ'].dt.date >= start_date.date()) & (df['ç™¼ç”Ÿæ—¥æœŸ'].dt.date <= end_date.date())
    filtered_df = df[mask]
    
    # æ’é™¤ç‰¹å®šä¸»æ©Ÿ
    if exclude_hosts:
        filtered_df = filtered_df[~filtered_df['ä¸»æ©Ÿ(Host)'].isin(exclude_hosts)]
    
    return filtered_df

def filter_data(df, start_date, end_date):
    """éæ¿¾æ•¸æ“šåŸºæ–¼æ—¥æœŸç¯„åœå’Œæ’é™¤çš„ä¸»æ©Ÿ"""
    # è½‰æ›æ—¥æœŸæ ¼å¼ç¢ºä¿å¯ä»¥æ¯”è¼ƒ
    start_date = pd.to_datetime(start_date)
    end_date = pd.to_datetime(end_date)
    
    # éæ¿¾æ—¥æœŸç¯„åœ
    mask = (df['ç™¼ç”Ÿæ—¥æœŸ'].dt.date >= start_date.date()) & (df['ç™¼ç”Ÿæ—¥æœŸ'].dt.date <= end_date.date())
    filtered_df = df[mask]
    
    return filtered_df

def create_dashboard():
    
    # è®€å–æ•¸æ“š
    df = load_data()
    if df is None:
        st.error("è«‹ä¸Šå‚³æœ‰æ•ˆçš„ CSV æˆ– Excel æª”æ¡ˆ")
        return
        
    st.subheader("ç³»çµ±ç›£æ§å„€è¡¨æ¿")

    # å–å¾—éŒ¯èª¤é¡å‹
    error_types = get_unique_error_types(df)

    # è¦æ’é™¤çš„æ¸¬è©¦ä¸»æ©Ÿåˆ—è¡¨
    EXCLUDED_HOSTS = ['Ai3-ECP-IDC-ECP-WebchatTest-192.168.211.5']
    
    # å´é‚Šæ¬„ - æ—¥æœŸéæ¿¾
    st.sidebar.header("éæ¿¾æ¢ä»¶")
    date_range = st.sidebar.date_input(
        "é¸æ“‡æ—¥æœŸç¯„åœ",
        [df['ç™¼ç”Ÿæ—¥æœŸ'].min().date(), df['ç™¼ç”Ÿæ—¥æœŸ'].max().date()]
    )
    
    # ç¢ºä¿æœ‰å…©å€‹æ—¥æœŸè¢«é¸æ“‡
    if len(date_range) == 2:
        start_date, end_date = date_range
        filtered_df_host = filter_data_host(df, start_date, end_date, EXCLUDED_HOSTS)
        filtered_df=filter_data(df, start_date, end_date)
    else:
        st.error("è«‹é¸æ“‡å®Œæ•´çš„æ—¥æœŸç¯„åœ")
        return
    
    # ä¸»æ©Ÿå‘Šè­¦çµ±è¨ˆ (å·²æ’é™¤æ¸¬è©¦ä¸»æ©Ÿ)
    host_alerts = filtered_df_host['ä¸»æ©Ÿ(Host)'].value_counts()
    top_5_hosts = host_alerts.head()
    
    # é ‚éƒ¨çµ±è¨ˆæ•¸å­—
    total_alerts = len(filtered_df_host)
    unique_hosts = filtered_df_host['ä¸»æ©Ÿ(Host)'].nunique()
    max_host_alerts = host_alerts.max() if not host_alerts.empty else 0
    
    col1, col2, col3= st.columns(3)
    with col1:
        st.metric("ç¸½å‘Šè­¦æ•¸", f"{total_alerts:,}")
    with col2:
        st.metric("å½±éŸ¿ä¸»æ©Ÿæ•¸", f"{unique_hosts:,}")
    with col3:
        st.metric("å–®ä¸»æ©Ÿæœ€é«˜å‘Šè­¦æ•¸", f"{max_host_alerts:,}")
    
    
    stats = calculate_stats(filtered_df)
    
    # å‰µå»ºçµ±è¨ˆè¡¨æ ¼
    st.subheader('ç•°å¸¸çµ±è¨ˆè¡¨')
    
    # ä½¿ç”¨ CSS ä¾†è¨­å®šè¡¨æ ¼æ¨£å¼
    st.markdown("""
    <style>
    .stats-table {
        width: 100%;
        border-collapse: collapse;
    }
    .stats-table th, .stats-table td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: center;
    }
    .stats-table th {
        background-color: #1e88e5;
        color: white;
    }
    .stats-table tr:nth-child(1) {
        background-color: #4CAF50;
        color: white;
    }
    .stats-table td {
        background-color: #f5f5f5;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # å‰µå»ºè¡¨æ ¼ HTML
    table_html = """
    <table class="stats-table">
        <tr>
            <th>è™•ç†æ–¹å¼</th>
            <th colspan="2">CPU</th>
            <th colspan="2">è¨˜æ†¶é«”</th>
            <th>ç¡¬ç¢Ÿ</th>
            <th>ç¶²é </th>
        </tr>
        <tr>
            <td></td>
            <td>VM CPU<br>>90%</td>
            <td>RDS CPU<br>>85%</td>
            <td>JVM<br>>80%</td>
            <td>ä¸»æ©Ÿå¯ç”¨è¨˜æ†¶é«”<br><500mb</td>
            <td>å¯ç”¨ç©ºé–“<br>>80%</td>
            <td>ç¶²é ç„¡æ³•<br>é€£ç·š</td>
        </tr>
        <tr>
            <td>å·²é€šçŸ¥å®¢æˆ¶<br>ä¸¦è™•ç†</td>
    """
    
    # æ·»åŠ æ•¸æ“šåˆ°è¡¨æ ¼
    for category in stats:
        for subcategory in stats[category]:
            table_html += f"<td>{stats[category][subcategory]}</td>"
    
    table_html += """
        </tr>
    </table>
    """
    st.markdown(table_html, unsafe_allow_html=True)
    # é¸æ“‡è¦é¡¯ç¤ºçš„æ¬„ä½
    st.write(f'*è¨­å‚™éšœç¤™æˆ–ç·šè·¯ç•°å¸¸éœ€æŸ¥çœ‹æœå‹™è«‹æ±‚ä»¥åŠæœ‰å ±ä¿®å±€ç«¯ä¹‹ç·šè·¯ï¼Œå…¶ä»–è«‹è‡ªè¡ŒæŸ¥çœ‹è©²æœˆï¼ˆé€±ï¼‰æ˜¯å¦æœ‰ç•°å¸¸')

    st.subheader('è©³ç´°è³‡æ–™')
    col1, col2 = st.columns([2, 1])
    with col1:
        # å‰µå»ºå¤šé¸æ¡†
        selected_errors = st.multiselect(
            'é¸æ“‡ç•°å¸¸é¡å‹',
            list(error_types.keys()),
            default=list(error_types.keys())
        )
    display_columns = ['æ—¥æœŸ', 'ä¸»æ©Ÿ(Host)', 'ç•°å¸¸è¨Šæ¯', 'ç•°å¸¸ç­‰ç´š', 'ä¸»ç®¡æˆ–è™•ç†äººå›æ‡‰']

    if selected_errors:
        mask = pd.Series(False, index=filtered_df.index)
        for error_key in selected_errors:
            mask |= filtered_df['ç•°å¸¸è¨Šæ¯'].str.contains(error_types[error_key], na=False)
        filtered_df = filtered_df[mask]
        
        # é¡¯ç¤ºç¯©é¸å¾Œçš„æ•¸æ“šï¼Œåªé¡¯ç¤ºæŒ‡å®šæ¬„ä½
        
        st.write(f'å…±æ‰¾åˆ° {len(filtered_df)} ç­†è¨˜éŒ„')
        st.dataframe(filtered_df[display_columns])

    # ä¸»è¦åœ–è¡¨å€åŸŸ
    chart_col1, chart_col2 = st.columns(2)
    
    with chart_col1:
        st.subheader("æ¯æ—¥å‘Šè­¦ç¸½æ•¸")
        daily_alerts = filtered_df_host.groupby('æ—¥æœŸ').size().reset_index(name='å‘Šè­¦æ¬¡æ•¸')
        fig_daily = px.line(daily_alerts, x='æ—¥æœŸ', y='å‘Šè­¦æ¬¡æ•¸',
                          template='plotly_white')
        fig_daily.update_layout(height=400)
        st.plotly_chart(fig_daily, use_container_width=True)
        
    with chart_col2:
        st.subheader("Top 5 å‘Šè­¦ä¸»æ©Ÿ")
        fig_top_hosts = go.Figure(data=[
            go.Bar(
                x=top_5_hosts.values,
                y=top_5_hosts.index,
                orientation='h',
                text=top_5_hosts.values,
                textposition='auto',
            )
        ])
        fig_top_hosts.update_layout(
            height=400,
            template='plotly_white',
            yaxis={'categoryorder':'total ascending'},
            xaxis_title="å‘Šè­¦æ¬¡æ•¸",
            yaxis_title="ä¸»æ©Ÿåç¨±"
        )
        st.plotly_chart(fig_top_hosts, use_container_width=True)
    
    # ç•°å¸¸åˆ†å¸ƒåœ“é¤…åœ–
    st.subheader("ç•°å¸¸ç­‰ç´šåˆ†å¸ƒ")
    severity_dist = filtered_df_host['ç•°å¸¸ç­‰ç´š'].value_counts()
    fig_severity = px.pie(
        values=severity_dist.values, 
        names=severity_dist.index,
        template='plotly_white'
    )
    fig_severity.update_layout(height=400)
    st.plotly_chart(fig_severity, use_container_width=True)
    
   
    # é¡¯ç¤ºé¸æ“‡çš„æ—¥æœŸç¯„åœ
    st.sidebar.write(f"ç•¶å‰é¡¯ç¤º: {start_date} åˆ° {end_date}")

if __name__ == "__main__":
    create_dashboard()